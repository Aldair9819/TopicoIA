{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import ImageDraw\n",
    "import PIL.Image as Image\n",
    "\n",
    "ruta = \"C:\\\\Users\\\\Waldosir\\\\Documents\\\\2doCodigo\\\\TopicoIA\\\\Marzo\\\\BD\\\\corpus_images\\\\bored\\\\61.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen en crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[173 175 172]\n",
      "  [173 175 172]\n",
      "  [173 175 172]\n",
      "  ...\n",
      "  [177 175 176]\n",
      "  [177 175 176]\n",
      "  [177 175 176]]\n",
      "\n",
      " [[173 175 172]\n",
      "  [173 175 172]\n",
      "  [173 175 172]\n",
      "  ...\n",
      "  [178 176 177]\n",
      "  [179 177 178]\n",
      "  [179 177 178]]\n",
      "\n",
      " [[173 175 172]\n",
      "  [173 175 172]\n",
      "  [173 175 172]\n",
      "  ...\n",
      "  [178 178 178]\n",
      "  [178 178 178]\n",
      "  [178 178 178]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[114  97 103]\n",
      "  [119 104 109]\n",
      "  [142 132 133]\n",
      "  ...\n",
      "  [130 132 129]\n",
      "  [130 132 129]\n",
      "  [129 131 128]]\n",
      "\n",
      " [[127 108 114]\n",
      "  [141 124 130]\n",
      "  [148 139 140]\n",
      "  ...\n",
      "  [132 132 130]\n",
      "  [131 131 129]\n",
      "  [131 131 129]]\n",
      "\n",
      " [[116  95 102]\n",
      "  [141 124 130]\n",
      "  [129 120 121]\n",
      "  ...\n",
      "  [131 131 129]\n",
      "  [131 131 129]\n",
      "  [131 131 129]]]\n"
     ]
    }
   ],
   "source": [
    "imagen = face_recognition.load_image_file(ruta)\n",
    "print(imagen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puntos de la cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(139, 386, 325, 201)]\n"
     ]
    }
   ],
   "source": [
    "face_locations = face_recognition.face_locations(imagen)\n",
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar imagen recortada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cara = face_locations[0]\n",
    "top, right, bottom, left = cara\n",
    "imagen_pil = Image.open(ruta)\n",
    "cara_recortada = imagen_pil.crop((left, top, right, bottom))\n",
    "#cara_recortada.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = Image.fromarray(imagen)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chin': [(92, 303), (98, 349), (111, 394), (123, 439), (136, 484), (159, 525), (189, 556), (226, 580), (265, 587), (302, 579), (337, 556), (365, 524), (388, 483), (403, 439), (415, 394), (427, 348), (432, 303)], 'left_eyebrow': [(122, 281), (147, 270), (173, 270), (199, 277), (224, 289)], 'right_eyebrow': [(306, 288), (331, 275), (357, 269), (383, 268), (407, 278)], 'nose_bridge': [(266, 326), (266, 359), (266, 393), (266, 426)], 'nose_tip': [(241, 442), (252, 447), (266, 452), (279, 447), (291, 442)], 'left_eye': [(154, 326), (173, 314), (196, 316), (214, 332), (193, 336), (171, 335)], 'right_eye': [(316, 330), (334, 314), (357, 312), (375, 324), (359, 333), (337, 334)], 'top_lip': [(208, 493), (230, 481), (251, 474), (267, 479), (283, 474), (301, 480), (323, 491), (312, 493), (283, 492), (266, 493), (250, 493), (219, 495)], 'bottom_lip': [(323, 491), (303, 510), (284, 520), (266, 522), (249, 521), (229, 511), (208, 493), (219, 495), (250, 494), (266, 496), (283, 493), (312, 493)]}]\n"
     ]
    }
   ],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(imagen)\n",
    "print(face_landmarks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chin is at these pixel locations: [(92, 303), (98, 349), (111, 394), (123, 439), (136, 484), (159, 525), (189, 556), (226, 580), (265, 587), (302, 579), (337, 556), (365, 524), (388, 483), (403, 439), (415, 394), (427, 348), (432, 303)]\n"
     ]
    }
   ],
   "source": [
    "for(face_landmarks) in face_landmarks_list:\n",
    "    print(\"The chin is at these pixel locations: {}\".format(face_landmarks['chin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chin: [(92, 303), (98, 349), (111, 394), (123, 439), (136, 484), (159, 525), (189, 556), (226, 580), (265, 587), (302, 579), (337, 556), (365, 524), (388, 483), (403, 439), (415, 394), (427, 348), (432, 303)]\n",
      "left_eyebrow: [(122, 281), (147, 270), (173, 270), (199, 277), (224, 289)]\n",
      "right_eyebrow: [(306, 288), (331, 275), (357, 269), (383, 268), (407, 278)]\n",
      "nose_bridge: [(266, 326), (266, 359), (266, 393), (266, 426)]\n",
      "nose_tip: [(241, 442), (252, 447), (266, 452), (279, 447), (291, 442)]\n",
      "left_eye: [(154, 326), (173, 314), (196, 316), (214, 332), (193, 336), (171, 335)]\n",
      "right_eye: [(316, 330), (334, 314), (357, 312), (375, 324), (359, 333), (337, 334)]\n",
      "top_lip: [(208, 493), (230, 481), (251, 474), (267, 479), (283, 474), (301, 480), (323, 491), (312, 493), (283, 492), (266, 493), (250, 493), (219, 495)]\n",
      "bottom_lip: [(323, 491), (303, 510), (284, 520), (266, 522), (249, 521), (229, 511), (208, 493), (219, 495), (250, 494), (266, 496), (283, 493), (312, 493)]\n"
     ]
    }
   ],
   "source": [
    "for clave, valor in face_landmarks_list[0].items():\n",
    "    print(clave + \":\", valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a combinarlo para hacer un dataset. Primero las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Waldosir\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorios encontrados:\n",
      "bored\n",
      "engaged\n",
      "excited\n",
      "focused\n",
      "interested\n",
      "relaxed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ruta al directorio principal donde se descomprimieron los archivos\n",
    "directorio_principal = \"C:\\\\Users\\\\Waldosir\\\\Documents\\\\2doCodigo\\\\TopicoIA\\\\Marzo\\\\BD\\\\corpus_images\"\n",
    "\n",
    "# Listar directorios en el directorio principal\n",
    "directorios = [nombre for nombre in os.listdir(directorio_principal) if os.path.isdir(os.path.join(directorio_principal, nombre))]\n",
    "\n",
    "# Imprimir los directorios encontrados\n",
    "print(\"Directorios encontrados:\")\n",
    "for directorio in directorios:\n",
    "    print(directorio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Recorrer cada carpeta dentro del directorio principal\\nfor carpeta in os.listdir(directorio_principal):\\n    carpeta_path = os.path.join(directorio_principal, carpeta)\\n\\n    # Verificar si es un directorio\\n    if os.path.isdir(carpeta_path):\\n        print(f\"Recorriendo imágenes en la carpeta: {carpeta}\")\\n\\n        # Recorrer cada archivo en la carpeta\\n        for archivo in os.listdir(carpeta_path):\\n\\n            archivo_path = os.path.join(carpeta_path, archivo)\\n\\n            # Verificar si es un archivo de imagen (puedes ajustar las extensiones según tus necesidades)\\n            if archivo.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\\n                print(f\"Procesando imagen: {archivo}\")\\n\\n                # Ejemplo de carga de imagen utilizando PIL\\n                #imagen = Image.open(archivo_path)\\n                imagen = face_recognition.load_image_file(archivo_path)\\n                \\n                # Puedes realizar operaciones con la imagen aquí, si es necesario\\n                face_locations = face_recognition.face_locations(imagen)\\n                print(face_locations)\\n\\n            break;\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ruta al directorio principal donde se descomprimieron los archivos\n",
    "\"\"\"\n",
    "# Recorrer cada carpeta dentro del directorio principal\n",
    "for carpeta in os.listdir(directorio_principal):\n",
    "    carpeta_path = os.path.join(directorio_principal, carpeta)\n",
    "\n",
    "    # Verificar si es un directorio\n",
    "    if os.path.isdir(carpeta_path):\n",
    "        print(f\"Recorriendo imágenes en la carpeta: {carpeta}\")\n",
    "\n",
    "        # Recorrer cada archivo en la carpeta\n",
    "        for archivo in os.listdir(carpeta_path):\n",
    "\n",
    "            archivo_path = os.path.join(carpeta_path, archivo)\n",
    "\n",
    "            # Verificar si es un archivo de imagen (puedes ajustar las extensiones según tus necesidades)\n",
    "            if archivo.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                print(f\"Procesando imagen: {archivo}\")\n",
    "\n",
    "                # Ejemplo de carga de imagen utilizando PIL\n",
    "                #imagen = Image.open(archivo_path)\n",
    "                imagen = face_recognition.load_image_file(archivo_path)\n",
    "                \n",
    "                # Puedes realizar operaciones con la imagen aquí, si es necesario\n",
    "                face_locations = face_recognition.face_locations(imagen)\n",
    "                print(face_locations)\n",
    "\n",
    "            break;\n",
    "\"\"\"\n",
    "# Recuerda ajustar las rutas y extensiones de archivo según tu estructura y necesidades específicas.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
